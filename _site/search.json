[
  {
    "objectID": "exanalysis.html",
    "href": "exanalysis.html",
    "title": "Example Analysis",
    "section": "",
    "text": "This analysis aims to predict individuals’ smoking status using multiple biochemical and body signal measures. The data set used for this analysis is obtained from Korea’s National Health Insurance Service (“Smoking and Drinking Dataset with Body Signal,” n.d.a, n.d.b). This analysis is intended for anyone interested in multinomial classification and prediction problems, especially in healthcare.\n\n\n\n\n# Loading Data set\nlibrary(readxl)\nlibrary(readr)\ndataset &lt;- read_csv(\"smoking_driking_dataset_Ver01.csv\", show_col_types = FALSE)\n\n\n# removing null values \nlibrary(tidyr)\ndataset &lt;- drop_na(dataset)\n# dimension of the data\ndim(dataset)\n\n[1] 991346     24\n\n\nThe data set includes almost a million observations and twenty-four variables.\n\n# Checking if the groups are balanced \nlibrary(dplyr)\ndataset %&gt;%\n    group_by(SMK_stat_type_cd) %&gt;%\n    tally()\n\n# A tibble: 3 × 2\n  SMK_stat_type_cd      n\n             &lt;dbl&gt;  &lt;int&gt;\n1                1 602441\n2                2 174951\n3                3 213954\n\n\nAs shown above the groups are not balanced. There are more observations with smoking status 1.\n\n\n\n\n\n\nNote\n\n\n\nUnbalanced groups can affect prediction accuracy.\n\n\nTo decrease run time, I will work on a sample of the data.\n\n# sampling 10000 observations\ndata_small &lt;- sample_n(dataset, 10000)\n\n\nglimpse(data_small)\n\nRows: 10,000\nColumns: 24\n$ sex              &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"…\n$ age              &lt;dbl&gt; 60, 45, 75, 25, 35, 55, 55, 60, 55, 60, 55, 40, 25, 6…\n$ height           &lt;dbl&gt; 170, 165, 150, 170, 170, 150, 165, 150, 165, 160, 165…\n$ weight           &lt;dbl&gt; 80, 60, 55, 75, 70, 60, 75, 40, 85, 70, 65, 60, 85, 5…\n$ waistline        &lt;dbl&gt; 95.0, 79.0, 80.0, 87.3, 76.0, 83.0, 90.1, 73.0, 100.0…\n$ sight_left       &lt;dbl&gt; 1.0, 0.5, 0.4, 1.2, 1.2, 0.5, 1.0, 1.0, 9.9, 0.9, 0.7…\n$ sight_right      &lt;dbl&gt; 1.2, 0.7, 0.5, 1.2, 0.8, 0.5, 1.0, 0.8, 9.9, 0.9, 0.4…\n$ hear_left        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ hear_right       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,…\n$ SBP              &lt;dbl&gt; 128, 128, 140, 115, 110, 130, 130, 139, 124, 122, 138…\n$ DBP              &lt;dbl&gt; 82, 89, 85, 72, 60, 72, 70, 80, 84, 70, 82, 73, 71, 8…\n$ BLDS             &lt;dbl&gt; 113, 120, 120, 82, 99, 103, 92, 101, 180, 141, 100, 9…\n$ tot_chole        &lt;dbl&gt; 217, 176, 196, 186, 189, 163, 183, 146, 158, 140, 169…\n$ HDL_chole        &lt;dbl&gt; 48, 70, 71, 48, 42, 48, 36, 42, 50, 85, 30, 48, 51, 5…\n$ LDL_chole        &lt;dbl&gt; 130, 89, 91, 98, 114, 75, 102, 78, 68, 40, 122, 78, 1…\n$ triglyceride     &lt;dbl&gt; 193, 79, 169, 198, 165, 198, 221, 129, 193, 77, 84, 1…\n$ hemoglobin       &lt;dbl&gt; 15.2, 13.3, 15.3, 16.2, 14.2, 13.4, 17.6, 13.0, 15.1,…\n$ urine_protein    &lt;dbl&gt; 4, 1, 1, 1, 1, 1, 1, 1, 3, 3, 2, 1, 1, 4, 1, 1, 1, 1,…\n$ serum_creatinine &lt;dbl&gt; 1.3, 0.7, 0.8, 1.1, 1.0, 0.8, 0.9, 0.7, 0.8, 0.9, 0.8…\n$ SGOT_AST         &lt;dbl&gt; 24, 28, 41, 26, 15, 44, 34, 24, 206, 19, 16, 19, 16, …\n$ SGOT_ALT         &lt;dbl&gt; 17, 17, 33, 27, 24, 52, 34, 23, 218, 19, 15, 21, 15, …\n$ gamma_GTP        &lt;dbl&gt; 32, 18, 19, 38, 20, 33, 36, 14, 326, 31, 20, 25, 20, …\n$ SMK_stat_type_cd &lt;dbl&gt; 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 3, 1, 1,…\n$ DRK_YN           &lt;chr&gt; \"Y\", \"Y\", \"N\", \"Y\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"Y\", \"N\"…\n\n\n\n# Converting DRK_YN  to numeric\ndata_small &lt;- data_small %&gt;% \n  mutate(DRK_YN = ifelse(DRK_YN==\"Y\",1,0))\n\nThe table below displays the data dictionary(“Data Dictionary,” n.d.; “Smoking and Drinking Dataset with Body Signal,” n.d.b).\n\nknitr::include_graphics(\"datadictionary.png\")\n\n\n\n\n\n# looking for correlated variables \nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\ncorrplot(cor(as.matrix(data_small[-c(1,23)])))\n\n\n\n\nAs the correlation plot depicts, the variables LDL_chole and tot_chole, DBP and SBP, and SGOT_ALT and SGOT_AST are highly correlated. Therefore, one of each pair will be excluded when fitting the prediction model.\n\n\nHighly correlated predictors can increase a model’s variance . A change in one variable will cause a change in another; therefore, small changes in the data might cause significant changes in the model and, thus, any predictions made using the model(Sonderegger 2020).\n\n# removing correlated predictors\ndata_small &lt;- select(data_small, -c('LDL_chole','SGOT_ALT','SBP'))\n\n\n\n\nBefore fitting a model, I will visualize the data. Since there are over twenty predictors, only a fraction will be visualized.\n\n# relationship between age,weight,and smoking status by sex\nlibrary(ggplot2)\nggplot(data_small, aes(x=age , y= weight,col= SMK_stat_type_cd )) +\n  geom_count(alpha = .7) + \n  facet_wrap(~sex, ncol=1) +\n  labs(title = \"Figure 1: Smoking Status Distribition\",\n       subtitle = \"Based on Age and Weight\",\n       color = \" Smoking State\", caption = \" In the legend,  1 =  never smoking, \n       2= used to smoke but quit, and 3 = still smoking.\") +\n  xlab(\"Age(in 5 year increments)\") +\n  ylab(\"Weight(kg)\") +\n  theme_minimal() \n\n\n\n\nThe plot above shows that more male than female smokers are represented in the data set. Furthermore, in both sexes, smokers are concentrated between the ages of 20 and 60.\nThe distribution of smokers can also be visualized by the bar graph bellow.\n\n#  distribution of smoking state by sex\nggplot(data_small, aes(x= SMK_stat_type_cd)) +\n  geom_bar( fill= \"lightblue\") + \n  facet_wrap(~sex, ncol=1) +\n  labs(title = \"Figure 2: Smoking Status Distribition\",\n       subtitle = \"Among Female and Male.\",\n        caption = \" In the legend,  1 =  never smoking, \n       2= used to smoke but quit, and 3 = still smoking.\") +\n  xlab(\"Smoking State\") +\n  ylab(\"Count\") +\n  theme_minimal()\n\n\n\n\n\n# visualizing the relationship between hemaglobin levels and smoking status by sex\nggplot(data_small, aes(x= SMK_stat_type_cd, y= hemoglobin )) +\n  geom_jitter(alpha = 0.7,color = \"lightblue\") + \n  facet_wrap(~sex, ncol=1) +\n  labs(title = \"Figure 3 :Smoking Status Distribition\",\n       subtitle = \"Based on Hemoglobin levels\",\n      caption = \" 1 =  never smoking, \n       2= used to smoke but quit, and 3 = still smoking.\") +\n  xlab(\"Smoking State\") +\n  ylab(\"Hemaglobin Level(g/dl )\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFigures two and three both show that the classes of smokers are not balanced. As mentioned previously this might affect the prediction model.\n\n\n\n\n\nTraining and Test Set\n\n# Splitting the data into 80% training and 20% testing set\nset.seed(1)\ns &lt;- sample(c(TRUE, FALSE), nrow(data_small), replace=TRUE, prob=c(0.8,0.2))\ntrain  &lt;- data_small[s, ]\ntest   &lt;- data_small[!s, ]\n\n\n# Checking dimensions\ndim(train)\n\n[1] 7932   21\n\n\n\n# Checking dimensions\ndim(test)\n\n[1] 2068   21\n\n\n\n# Fitting a logistic regression model\nlibrary(nnet)\nmodel &lt;- multinom(SMK_stat_type_cd~. , data=data_small)\n\n# weights:  66 (42 variable)\ninitial  value 10986.122887 \niter  10 value 8673.724060\niter  20 value 8250.640034\niter  30 value 7458.658271\niter  40 value 6754.881728\niter  50 value 6586.436470\nfinal  value 6586.433911 \nconverged\n\nsummary(model)\n\nCall:\nmultinom(formula = SMK_stat_type_cd ~ ., data = data_small)\n\nCoefficients:\n  (Intercept)  sexMale         age     height       weight   waistline\n2  -10.620409 2.925871  0.02593050 0.03090314 -0.001900417 0.005839472\n3   -8.685562 2.626920 -0.01472591 0.03531417 -0.025765405 0.006479847\n   sight_left sight_right hear_left hear_right          DBP        BLDS\n2 -0.06820359  0.10671464 0.1044548 -0.2464631 -0.001663288 0.003170911\n3 -0.10276378  0.07964418 0.3782790 -0.7167674 -0.005971759 0.001347542\n      tot_chole    HDL_chole triglyceride hemoglobin urine_protein\n2  0.0004332052 -0.003980560  0.000706877 0.02139296   -0.06740609\n3 -0.0023024710 -0.006482351  0.002411808 0.18785655    0.03622582\n  serum_creatinine     SGOT_AST   gamma_GTP    DRK_YN\n2      -0.01594413 -0.004357052 0.002697511 0.8997814\n3      -0.08902891 -0.011644103 0.005090166 0.9059403\n\nStd. Errors:\n  (Intercept)   sexMale         age      height      weight   waistline\n2 0.006787641 0.1245859 0.003102926 0.003372770 0.005642170 0.006728727\n3 0.008857996 0.1127778 0.002990206 0.003308721 0.005430747 0.006553603\n  sight_left sight_right hear_left hear_right         DBP        BLDS\n2 0.04543168  0.04502619 0.2094327  0.2169149 0.003558236 0.001402729\n3 0.05541398  0.05122702 0.2258313  0.2548453 0.003477884 0.001423862\n     tot_chole   HDL_chole triglyceride hemoglobin urine_protein\n2 0.0009641207 0.002836105 0.0004409006 0.02918514    0.07347282\n3 0.0009447949 0.002744852 0.0004051826 0.02928019    0.07024143\n  serum_creatinine    SGOT_AST    gamma_GTP     DRK_YN\n2       0.07710696 0.002612902 0.0008741907 0.07351619\n3       0.09077964 0.002932718 0.0008407197 0.07017520\n\nResidual Deviance: 13172.87 \nAIC: 13256.87 \n\n\n\n# obtaining estimated probabilities \nprobablities &lt;- fitted(model)\n# making predictions\npredictions &lt;- predict(object=model, newdata=test, type=\"class\")\n# Confusion matrix \nconfusion_matrix &lt;- table(Predicted= predictions,\n                   True=test$SMK_stat_type_cd)\nconfusion_matrix\n\n         True\nPredicted    1    2    3\n        1 1020  110  118\n        2   83  111   63\n        3  143  129  291\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe model is more accurate in predicting the smoking status of individuals in Group 1(never smoking). The difference in prediction accuracy among the three groups is partly because of the class imbalance.\n\n\n\n# Test Error\ntest_error &lt;- mean(predictions!= test$SMK_stat_type_cd )\ntest_error\n\n[1] 0.3123791\n\n\nThe model has an \\(31.76\\%\\) testing classification error rate.\n\n\n# Calculating accuracy of the method \nround((sum(diag(confusion_matrix))/sum(confusion_matrix))*100,2)\n\n[1] 68.76\n\n\nThe model has an \\(68.23\\%\\) overall classification accuracy.\n\n\n\n\nIn this analysis, logistic regression was used to predict the smoking status of individuals using biochemical and body signal measures. The model’s prediction accuracy was \\(68.23\\%\\), and the testing classification error rate was \\(31.76\\%\\). The prediction accuracy could be increased by fitting a logistic regression model using a balanced training set. Other classification techniques such as lasso, discriminant analysis, or tree-based methods could also be employed to develop a model with better prediction accuracy.\n\n\ndplyr - sample_n(), glimpse(), group_by(), tally(), select(), mutate()   tidyr - drop_na()\nggplot - geom_count(), geom_bar(), geom_jitter(), facet_wrap()\ncorrplot - corrplot()\nnnet - multinom()"
  },
  {
    "objectID": "exanalysis.html#introduction",
    "href": "exanalysis.html#introduction",
    "title": "Example Analysis",
    "section": "",
    "text": "This analysis aims to predict individuals’ smoking status using multiple biochemical and body signal measures. The data set used for this analysis is obtained from Korea’s National Health Insurance Service (“Smoking and Drinking Dataset with Body Signal,” n.d.a, n.d.b). This analysis is intended for anyone interested in multinomial classification and prediction problems, especially in healthcare."
  },
  {
    "objectID": "exanalysis.html#exploring-the-data-set",
    "href": "exanalysis.html#exploring-the-data-set",
    "title": "Example Analysis",
    "section": "",
    "text": "# Loading Data set\nlibrary(readxl)\nlibrary(readr)\ndataset &lt;- read_csv(\"smoking_driking_dataset_Ver01.csv\", show_col_types = FALSE)\n\n\n# removing null values \nlibrary(tidyr)\ndataset &lt;- drop_na(dataset)\n# dimension of the data\ndim(dataset)\n\n[1] 991346     24\n\n\nThe data set includes almost a million observations and twenty-four variables.\n\n# Checking if the groups are balanced \nlibrary(dplyr)\ndataset %&gt;%\n    group_by(SMK_stat_type_cd) %&gt;%\n    tally()\n\n# A tibble: 3 × 2\n  SMK_stat_type_cd      n\n             &lt;dbl&gt;  &lt;int&gt;\n1                1 602441\n2                2 174951\n3                3 213954\n\n\nAs shown above the groups are not balanced. There are more observations with smoking status 1.\n\n\n\n\n\n\nNote\n\n\n\nUnbalanced groups can affect prediction accuracy.\n\n\nTo decrease run time, I will work on a sample of the data.\n\n# sampling 10000 observations\ndata_small &lt;- sample_n(dataset, 10000)\n\n\nglimpse(data_small)\n\nRows: 10,000\nColumns: 24\n$ sex              &lt;chr&gt; \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"…\n$ age              &lt;dbl&gt; 60, 45, 75, 25, 35, 55, 55, 60, 55, 60, 55, 40, 25, 6…\n$ height           &lt;dbl&gt; 170, 165, 150, 170, 170, 150, 165, 150, 165, 160, 165…\n$ weight           &lt;dbl&gt; 80, 60, 55, 75, 70, 60, 75, 40, 85, 70, 65, 60, 85, 5…\n$ waistline        &lt;dbl&gt; 95.0, 79.0, 80.0, 87.3, 76.0, 83.0, 90.1, 73.0, 100.0…\n$ sight_left       &lt;dbl&gt; 1.0, 0.5, 0.4, 1.2, 1.2, 0.5, 1.0, 1.0, 9.9, 0.9, 0.7…\n$ sight_right      &lt;dbl&gt; 1.2, 0.7, 0.5, 1.2, 0.8, 0.5, 1.0, 0.8, 9.9, 0.9, 0.4…\n$ hear_left        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ hear_right       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,…\n$ SBP              &lt;dbl&gt; 128, 128, 140, 115, 110, 130, 130, 139, 124, 122, 138…\n$ DBP              &lt;dbl&gt; 82, 89, 85, 72, 60, 72, 70, 80, 84, 70, 82, 73, 71, 8…\n$ BLDS             &lt;dbl&gt; 113, 120, 120, 82, 99, 103, 92, 101, 180, 141, 100, 9…\n$ tot_chole        &lt;dbl&gt; 217, 176, 196, 186, 189, 163, 183, 146, 158, 140, 169…\n$ HDL_chole        &lt;dbl&gt; 48, 70, 71, 48, 42, 48, 36, 42, 50, 85, 30, 48, 51, 5…\n$ LDL_chole        &lt;dbl&gt; 130, 89, 91, 98, 114, 75, 102, 78, 68, 40, 122, 78, 1…\n$ triglyceride     &lt;dbl&gt; 193, 79, 169, 198, 165, 198, 221, 129, 193, 77, 84, 1…\n$ hemoglobin       &lt;dbl&gt; 15.2, 13.3, 15.3, 16.2, 14.2, 13.4, 17.6, 13.0, 15.1,…\n$ urine_protein    &lt;dbl&gt; 4, 1, 1, 1, 1, 1, 1, 1, 3, 3, 2, 1, 1, 4, 1, 1, 1, 1,…\n$ serum_creatinine &lt;dbl&gt; 1.3, 0.7, 0.8, 1.1, 1.0, 0.8, 0.9, 0.7, 0.8, 0.9, 0.8…\n$ SGOT_AST         &lt;dbl&gt; 24, 28, 41, 26, 15, 44, 34, 24, 206, 19, 16, 19, 16, …\n$ SGOT_ALT         &lt;dbl&gt; 17, 17, 33, 27, 24, 52, 34, 23, 218, 19, 15, 21, 15, …\n$ gamma_GTP        &lt;dbl&gt; 32, 18, 19, 38, 20, 33, 36, 14, 326, 31, 20, 25, 20, …\n$ SMK_stat_type_cd &lt;dbl&gt; 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 3, 1, 1,…\n$ DRK_YN           &lt;chr&gt; \"Y\", \"Y\", \"N\", \"Y\", \"Y\", \"N\", \"Y\", \"N\", \"Y\", \"Y\", \"N\"…\n\n\n\n# Converting DRK_YN  to numeric\ndata_small &lt;- data_small %&gt;% \n  mutate(DRK_YN = ifelse(DRK_YN==\"Y\",1,0))\n\nThe table below displays the data dictionary(“Data Dictionary,” n.d.; “Smoking and Drinking Dataset with Body Signal,” n.d.b).\n\nknitr::include_graphics(\"datadictionary.png\")\n\n\n\n\n\n# looking for correlated variables \nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\ncorrplot(cor(as.matrix(data_small[-c(1,23)])))\n\n\n\n\nAs the correlation plot depicts, the variables LDL_chole and tot_chole, DBP and SBP, and SGOT_ALT and SGOT_AST are highly correlated. Therefore, one of each pair will be excluded when fitting the prediction model.\n\n\nHighly correlated predictors can increase a model’s variance . A change in one variable will cause a change in another; therefore, small changes in the data might cause significant changes in the model and, thus, any predictions made using the model(Sonderegger 2020).\n\n# removing correlated predictors\ndata_small &lt;- select(data_small, -c('LDL_chole','SGOT_ALT','SBP'))"
  },
  {
    "objectID": "exanalysis.html#visualizing-the-data",
    "href": "exanalysis.html#visualizing-the-data",
    "title": "Example Analysis",
    "section": "",
    "text": "Before fitting a model, I will visualize the data. Since there are over twenty predictors, only a fraction will be visualized.\n\n# relationship between age,weight,and smoking status by sex\nlibrary(ggplot2)\nggplot(data_small, aes(x=age , y= weight,col= SMK_stat_type_cd )) +\n  geom_count(alpha = .7) + \n  facet_wrap(~sex, ncol=1) +\n  labs(title = \"Figure 1: Smoking Status Distribition\",\n       subtitle = \"Based on Age and Weight\",\n       color = \" Smoking State\", caption = \" In the legend,  1 =  never smoking, \n       2= used to smoke but quit, and 3 = still smoking.\") +\n  xlab(\"Age(in 5 year increments)\") +\n  ylab(\"Weight(kg)\") +\n  theme_minimal() \n\n\n\n\nThe plot above shows that more male than female smokers are represented in the data set. Furthermore, in both sexes, smokers are concentrated between the ages of 20 and 60.\nThe distribution of smokers can also be visualized by the bar graph bellow.\n\n#  distribution of smoking state by sex\nggplot(data_small, aes(x= SMK_stat_type_cd)) +\n  geom_bar( fill= \"lightblue\") + \n  facet_wrap(~sex, ncol=1) +\n  labs(title = \"Figure 2: Smoking Status Distribition\",\n       subtitle = \"Among Female and Male.\",\n        caption = \" In the legend,  1 =  never smoking, \n       2= used to smoke but quit, and 3 = still smoking.\") +\n  xlab(\"Smoking State\") +\n  ylab(\"Count\") +\n  theme_minimal()\n\n\n\n\n\n# visualizing the relationship between hemaglobin levels and smoking status by sex\nggplot(data_small, aes(x= SMK_stat_type_cd, y= hemoglobin )) +\n  geom_jitter(alpha = 0.7,color = \"lightblue\") + \n  facet_wrap(~sex, ncol=1) +\n  labs(title = \"Figure 3 :Smoking Status Distribition\",\n       subtitle = \"Based on Hemoglobin levels\",\n      caption = \" 1 =  never smoking, \n       2= used to smoke but quit, and 3 = still smoking.\") +\n  xlab(\"Smoking State\") +\n  ylab(\"Hemaglobin Level(g/dl )\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFigures two and three both show that the classes of smokers are not balanced. As mentioned previously this might affect the prediction model."
  },
  {
    "objectID": "exanalysis.html#fitting-a-model-logistic-regression",
    "href": "exanalysis.html#fitting-a-model-logistic-regression",
    "title": "Example Analysis",
    "section": "",
    "text": "Training and Test Set\n\n# Splitting the data into 80% training and 20% testing set\nset.seed(1)\ns &lt;- sample(c(TRUE, FALSE), nrow(data_small), replace=TRUE, prob=c(0.8,0.2))\ntrain  &lt;- data_small[s, ]\ntest   &lt;- data_small[!s, ]\n\n\n# Checking dimensions\ndim(train)\n\n[1] 7932   21\n\n\n\n# Checking dimensions\ndim(test)\n\n[1] 2068   21\n\n\n\n# Fitting a logistic regression model\nlibrary(nnet)\nmodel &lt;- multinom(SMK_stat_type_cd~. , data=data_small)\n\n# weights:  66 (42 variable)\ninitial  value 10986.122887 \niter  10 value 8673.724060\niter  20 value 8250.640034\niter  30 value 7458.658271\niter  40 value 6754.881728\niter  50 value 6586.436470\nfinal  value 6586.433911 \nconverged\n\nsummary(model)\n\nCall:\nmultinom(formula = SMK_stat_type_cd ~ ., data = data_small)\n\nCoefficients:\n  (Intercept)  sexMale         age     height       weight   waistline\n2  -10.620409 2.925871  0.02593050 0.03090314 -0.001900417 0.005839472\n3   -8.685562 2.626920 -0.01472591 0.03531417 -0.025765405 0.006479847\n   sight_left sight_right hear_left hear_right          DBP        BLDS\n2 -0.06820359  0.10671464 0.1044548 -0.2464631 -0.001663288 0.003170911\n3 -0.10276378  0.07964418 0.3782790 -0.7167674 -0.005971759 0.001347542\n      tot_chole    HDL_chole triglyceride hemoglobin urine_protein\n2  0.0004332052 -0.003980560  0.000706877 0.02139296   -0.06740609\n3 -0.0023024710 -0.006482351  0.002411808 0.18785655    0.03622582\n  serum_creatinine     SGOT_AST   gamma_GTP    DRK_YN\n2      -0.01594413 -0.004357052 0.002697511 0.8997814\n3      -0.08902891 -0.011644103 0.005090166 0.9059403\n\nStd. Errors:\n  (Intercept)   sexMale         age      height      weight   waistline\n2 0.006787641 0.1245859 0.003102926 0.003372770 0.005642170 0.006728727\n3 0.008857996 0.1127778 0.002990206 0.003308721 0.005430747 0.006553603\n  sight_left sight_right hear_left hear_right         DBP        BLDS\n2 0.04543168  0.04502619 0.2094327  0.2169149 0.003558236 0.001402729\n3 0.05541398  0.05122702 0.2258313  0.2548453 0.003477884 0.001423862\n     tot_chole   HDL_chole triglyceride hemoglobin urine_protein\n2 0.0009641207 0.002836105 0.0004409006 0.02918514    0.07347282\n3 0.0009447949 0.002744852 0.0004051826 0.02928019    0.07024143\n  serum_creatinine    SGOT_AST    gamma_GTP     DRK_YN\n2       0.07710696 0.002612902 0.0008741907 0.07351619\n3       0.09077964 0.002932718 0.0008407197 0.07017520\n\nResidual Deviance: 13172.87 \nAIC: 13256.87 \n\n\n\n# obtaining estimated probabilities \nprobablities &lt;- fitted(model)\n# making predictions\npredictions &lt;- predict(object=model, newdata=test, type=\"class\")\n# Confusion matrix \nconfusion_matrix &lt;- table(Predicted= predictions,\n                   True=test$SMK_stat_type_cd)\nconfusion_matrix\n\n         True\nPredicted    1    2    3\n        1 1020  110  118\n        2   83  111   63\n        3  143  129  291\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe model is more accurate in predicting the smoking status of individuals in Group 1(never smoking). The difference in prediction accuracy among the three groups is partly because of the class imbalance.\n\n\n\n# Test Error\ntest_error &lt;- mean(predictions!= test$SMK_stat_type_cd )\ntest_error\n\n[1] 0.3123791\n\n\nThe model has an \\(31.76\\%\\) testing classification error rate.\n\n\n# Calculating accuracy of the method \nround((sum(diag(confusion_matrix))/sum(confusion_matrix))*100,2)\n\n[1] 68.76\n\n\nThe model has an \\(68.23\\%\\) overall classification accuracy."
  },
  {
    "objectID": "exanalysis.html#summary",
    "href": "exanalysis.html#summary",
    "title": "Example Analysis",
    "section": "",
    "text": "In this analysis, logistic regression was used to predict the smoking status of individuals using biochemical and body signal measures. The model’s prediction accuracy was \\(68.23\\%\\), and the testing classification error rate was \\(31.76\\%\\). The prediction accuracy could be increased by fitting a logistic regression model using a balanced training set. Other classification techniques such as lasso, discriminant analysis, or tree-based methods could also be employed to develop a model with better prediction accuracy.\n\n\ndplyr - sample_n(), glimpse(), group_by(), tally(), select(), mutate()   tidyr - drop_na()\nggplot - geom_count(), geom_bar(), geom_jitter(), facet_wrap()\ncorrplot - corrplot()\nnnet - multinom()"
  },
  {
    "objectID": "Project1_Yimenu.html",
    "href": "Project1_Yimenu.html",
    "title": "Project 1",
    "section": "",
    "text": "Link to GitHub Repository: https://github.com/MeklitYimenu/biostat777-intro--meklit---yimenu-.git"
  },
  {
    "objectID": "Project1_Yimenu.html#part-1",
    "href": "Project1_Yimenu.html#part-1",
    "title": "Project 1",
    "section": "",
    "text": "Link to GitHub Repository: https://github.com/MeklitYimenu/biostat777-intro--meklit---yimenu-.git"
  },
  {
    "objectID": "Project1_Yimenu.html#part-2",
    "href": "Project1_Yimenu.html#part-2",
    "title": "Project 1",
    "section": "Part 2",
    "text": "Part 2\nQuestion: What is your goal?\nI have two related research goals. One is to I especially want to contribute to integrating -omics data( such as genomic, transcriptomic, epigenomic, etc.) with genetic data (such as GWAS ). Such integration would aim to detect whether genetic variants identified as bio-markers affect gene expression, gene regulation, and cellular metabolism and how these effects relate to phenotype.\nMy second goal is to use genetic and genomic data obtained from diverse populations. I am passionate about the representation of diverse communities in medical and healthcare research. Thus, using data from diverse populations in my research is important to me. Furthermore, a data analysis method developed using a homogeneous population might be universally effective because different populations have different genetic variations.\nRegarding my long-term goal, I wish to contribute to statistical risk factor estimation methods for diseases with multiple bio-markers, especially cancer. I also want to collaborate with other researchers in diverse fields such as environmental health, health policy, and social sciences to incorporate social determinants of health with the risk factor prediction method."
  },
  {
    "objectID": "Project1_Yimenu.html#part-3",
    "href": "Project1_Yimenu.html#part-3",
    "title": "Project 1",
    "section": "Part 3",
    "text": "Part 3"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Meklit Yimenu",
    "section": "",
    "text": "My name is Meklit Yimenu, and I am from Addis Ababa, Ethiopia. I am a first-year PhD student in Biostatistics at the Bloomberg School of Public Health. I am interested in statistical genomics and genetics research. My hobbies include visiting art museums, listening to vintage records, reading, and ceramics/pottery.\n\nknitr::include_graphics(\"profilephotoSmall.png\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Educatioal Background\nI graduated from Lake Forest College with a bachelor’s in biochemistry, molecular biology, and mathematics. During my undergraduate degree, I conducted research in molecular genetics. I worked in Karen Kirk Lab starting the summer of my first year. During my junior year, I started working on research for my senior thesis titled “Telomerase Expression Dramatically Increases during Sexual Development.” I also attended and presented at multiple ASBMB (American Society of Biochemistry and Molecular Biology) conferences during this time.\n\n\nEducational Goal\nWhile working in genetic research, I often encountered statistical methods used to analyze sequencing data. This helped me discover statistical genomics and genetics and I became more interested in those fields. Therefore, I decided to pursue a Ph.D. in biostatistics.\n\n\nProffesional Goal\nMy professional goal is to develop biomarker identification and risk factor prediction methods by integrating -omics and genetic data."
  }
]